{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```NoteBook Focus```\n",
    "---\n",
    "1. Train numerous models to select best models for hypertuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```Imports```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from classifiers import classify\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```Creating new dataframe with balanced classes```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accgdln</th>\n",
       "      <th>age</th>\n",
       "      <th>altdum</th>\n",
       "      <th>amendyr</th>\n",
       "      <th>amttotal</th>\n",
       "      <th>casetype</th>\n",
       "      <th>citwhere</th>\n",
       "      <th>combdrg2</th>\n",
       "      <th>crimhist</th>\n",
       "      <th>disposit</th>\n",
       "      <th>...</th>\n",
       "      <th>typemony</th>\n",
       "      <th>typeoths</th>\n",
       "      <th>unit1</th>\n",
       "      <th>mwgt1</th>\n",
       "      <th>wgt1</th>\n",
       "      <th>xcrhissr</th>\n",
       "      <th>xfolsor</th>\n",
       "      <th>xmaxsor</th>\n",
       "      <th>xminsor</th>\n",
       "      <th>sentrnge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.356099e+07</td>\n",
       "      <td>85104.433315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.193400e+06</td>\n",
       "      <td>5967.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.030000e+04</td>\n",
       "      <td>4.120000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.692000e+05</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accgdln   age  altdum  amendyr  amttotal  casetype  citwhere  combdrg2  \\\n",
       "0      1.0  20.0       0   2018.0         0       1.0     211.0       6.0   \n",
       "1      1.0  64.0       0   2018.0         0       1.0     211.0       1.0   \n",
       "2      1.0  28.0       0   2018.0         0       1.0     211.0       3.0   \n",
       "3      2.0  55.0       0   2018.0         0       1.0     211.0      77.0   \n",
       "4      1.0  30.0       0   2018.0         0       1.0     211.0       6.0   \n",
       "\n",
       "   crimhist  disposit  ...  typemony  typeoths  unit1         mwgt1  \\\n",
       "0       1.0         1  ...       1.0         0    1.0  6.356099e+07   \n",
       "1       1.0         1  ...       1.0         0    1.0  1.193400e+06   \n",
       "2       1.0         1  ...       1.0         0    2.0  2.000000e+06   \n",
       "3       1.0         1  ...       1.0         0    1.0  1.030000e+04   \n",
       "4       1.0         1  ...       1.0         0    1.0  1.692000e+05   \n",
       "\n",
       "           wgt1  xcrhissr  xfolsor  xmaxsor  xminsor  sentrnge  \n",
       "0  85104.433315       1.0     17.0     30.0     24.0       8.0  \n",
       "1   5967.000000       3.0     27.0    108.0     87.0       0.0  \n",
       "2   2000.000000       6.0     27.0    162.0    130.0       2.0  \n",
       "3      4.120000       5.0     13.0     37.0     30.0       0.0  \n",
       "4     84.600000       6.0     25.0    137.0    110.0       2.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs = pd.read_csv('../drugs_2020_simply_imputed.csv')\n",
    "drugs.drop(columns=['Unnamed: 0','Unnamed: 0.1'], inplace=True)\n",
    "drugs.columns = drugs.columns.str.lower()\n",
    "drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accgdln     0\n",
       "age         0\n",
       "altdum      0\n",
       "amendyr     0\n",
       "amttotal    0\n",
       "           ..\n",
       "xcrhissr    0\n",
       "xfolsor     0\n",
       "xmaxsor     0\n",
       "xminsor     0\n",
       "sentrnge    0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values Claire might've missed before modeling\n",
    "drugs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(754, 65)\n",
      "(754, 65)\n",
      "(1508, 65)\n"
     ]
    }
   ],
   "source": [
    "# concatting new df with equal classes for modeling\n",
    "\n",
    "# separate all minor classes\n",
    "df_0 = drugs[drugs['prisdum']==0]\n",
    "print(df_0.shape)\n",
    "\n",
    "# separate all majority class and sample 754 to match minor class\n",
    "df_1 = drugs[drugs['prisdum']==1]\n",
    "df_1_sample = df_1.sample(n=754, replace=False)\n",
    "print(df_1_sample.shape)\n",
    "\n",
    "# concat both df's\n",
    "equal_class_df = pd.concat([df_0,df_1_sample], ignore_index=True)\n",
    "print(equal_class_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```Modeling```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with balanced classes\n",
    "\n",
    "#set up X/y\n",
    "X = equal_class_df.drop(columns='prisdum')\n",
    "y = equal_class_df['prisdum']\n",
    "\n",
    "# set train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42, train_size=0.7, stratify=y)\n",
    "\n",
    "# scale data\n",
    "ss = StandardScaler()\n",
    "X_train_ss = ss.fit_transform(X_train)\n",
    "X_test_ss = ss.fit_transform(X_test)\n",
    "\n",
    "# train multiple models\n",
    "equal_class_scores = classify(X_train_ss,X_test_ss,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Acc-diff</th>\n",
       "      <th>Train-F1</th>\n",
       "      <th>Test-F1</th>\n",
       "      <th>F1-diff</th>\n",
       "      <th>Train-Pres</th>\n",
       "      <th>Test-Pres</th>\n",
       "      <th>Pres-diff</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Test-Recall</th>\n",
       "      <th>Recall_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.984834</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.008543</td>\n",
       "      <td>0.984791</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.008616</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.981061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.998104</td>\n",
       "      <td>0.995585</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.998106</td>\n",
       "      <td>0.995595</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.998106</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.998106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>0.046358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955603</td>\n",
       "      <td>0.044397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914980</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_knn</th>\n",
       "      <td>0.984834</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.008543</td>\n",
       "      <td>0.984820</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.008558</td>\n",
       "      <td>0.986692</td>\n",
       "      <td>0.991189</td>\n",
       "      <td>0.004497</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.012621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_log</th>\n",
       "      <td>0.995261</td>\n",
       "      <td>0.997792</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.995279</td>\n",
       "      <td>0.997792</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.992467</td>\n",
       "      <td>0.995595</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.998106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995585</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995595</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997792</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997792</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995595</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>0.046358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955603</td>\n",
       "      <td>0.044397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914980</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gboost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>0.046358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955603</td>\n",
       "      <td>0.044397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914980</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.995261</td>\n",
       "      <td>0.988962</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.995270</td>\n",
       "      <td>0.989059</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.994329</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.015974</td>\n",
       "      <td>0.996212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc  Test Acc  Acc-diff  Train-F1   Test-F1   F1-diff  \\\n",
       "knn       0.984834  0.993377  0.008543  0.984791  0.993407  0.008616   \n",
       "logreg    0.998104  0.995585  0.002519  0.998106  0.995595  0.002511   \n",
       "dt        1.000000  0.953642  0.046358  1.000000  0.955603  0.044397   \n",
       "bag       1.000000  0.991170  0.008830  1.000000  0.991228  0.008772   \n",
       "bag_knn   0.984834  0.993377  0.008543  0.984820  0.993377  0.008558   \n",
       "bag_log   0.995261  0.997792  0.002532  0.995279  0.997792  0.002514   \n",
       "rf        1.000000  0.995585  0.004415  1.000000  0.995595  0.004405   \n",
       "et        1.000000  0.997792  0.002208  1.000000  0.997792  0.002208   \n",
       "ada       1.000000  0.953642  0.046358  1.000000  0.955603  0.044397   \n",
       "gboost    1.000000  0.953642  0.046358  1.000000  0.955603  0.044397   \n",
       "svc       0.995261  0.988962  0.006298  0.995270  0.989059  0.006211   \n",
       "\n",
       "         Train-Pres  Test-Pres  Pres-diff  Train_Recall  Test-Recall  \\\n",
       "knn        0.988550   0.986900   0.001650      0.981061     1.000000   \n",
       "logreg     0.998106   0.991228   0.006878      0.998106     1.000000   \n",
       "dt         1.000000   0.914980   0.085020      1.000000     1.000000   \n",
       "bag        1.000000   0.982609   0.017391      1.000000     1.000000   \n",
       "bag_knn    0.986692   0.991189   0.004497      0.982955     0.995575   \n",
       "bag_log    0.992467   0.995595   0.003128      0.998106     1.000000   \n",
       "rf         1.000000   0.991228   0.008772      1.000000     1.000000   \n",
       "et         1.000000   0.995595   0.004405      1.000000     1.000000   \n",
       "ada        1.000000   0.914980   0.085020      1.000000     1.000000   \n",
       "gboost     1.000000   0.914980   0.085020      1.000000     1.000000   \n",
       "svc        0.994329   0.978355   0.015974      0.996212     1.000000   \n",
       "\n",
       "         Recall_diff  \n",
       "knn         0.018939  \n",
       "logreg      0.001894  \n",
       "dt          0.000000  \n",
       "bag         0.000000  \n",
       "bag_knn     0.012621  \n",
       "bag_log     0.001894  \n",
       "rf          0.000000  \n",
       "et          0.000000  \n",
       "ada         0.000000  \n",
       "gboost      0.000000  \n",
       "svc         0.003788  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_class_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.9981042654028436\n",
      "test acc: 0.9955849889624724\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate, train, evaluate\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_ss,y_train)\n",
    "print(f\"train acc: {logreg.score(X_train_ss,y_train)}\")\n",
    "print(f\"test acc: {logreg.score(X_test_ss,y_test)}\")\n",
    "\n",
    "# create df to visualize coefs\n",
    "logreg_scores = pd.DataFrame(columns=X.columns,data=logreg.coef_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>suprdum</th>\n",
       "      <td>1.684704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suprel</th>\n",
       "      <td>0.895133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senspcap</th>\n",
       "      <td>0.767858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensplt0</th>\n",
       "      <td>0.767858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totchpts</th>\n",
       "      <td>0.484990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numdepen</th>\n",
       "      <td>0.439572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combdrg2</th>\n",
       "      <td>0.401361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timservc</th>\n",
       "      <td>0.371470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newcit</th>\n",
       "      <td>0.348658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district</th>\n",
       "      <td>0.288835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "suprdum   1.684704\n",
       "suprel    0.895133\n",
       "senspcap  0.767858\n",
       "sensplt0  0.767858\n",
       "totchpts  0.484990\n",
       "numdepen  0.439572\n",
       "combdrg2  0.401361\n",
       "timservc  0.371470\n",
       "newcit    0.348658\n",
       "district  0.288835"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_scores[logreg_scores[0]>0].sort_values(by=0,ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crivera/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/crivera/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/crivera/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/crivera/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/crivera/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/crivera/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/crivera/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/crivera/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/crivera/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/crivera/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# model with UN_balanced classes\n",
    "\n",
    "#set up X/y\n",
    "X = drugs.drop(columns='prisdum')\n",
    "y = drugs['prisdum']\n",
    "\n",
    "# set train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42, train_size=0.7, stratify=y)\n",
    "\n",
    "# scale data\n",
    "ss = StandardScaler()\n",
    "X_train_ss = ss.fit_transform(X_train)\n",
    "X_test_ss = ss.fit_transform(X_test)\n",
    "\n",
    "# train multiple models\n",
    "unbalanced_class_scores = classify(X_train_ss,X_test_ss,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Acc-diff</th>\n",
       "      <th>Train-F1</th>\n",
       "      <th>Test-F1</th>\n",
       "      <th>F1-diff</th>\n",
       "      <th>Train-Pres</th>\n",
       "      <th>Test-Pres</th>\n",
       "      <th>Pres-diff</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Test-Recall</th>\n",
       "      <th>Recall_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.998217</td>\n",
       "      <td>0.998614</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.999067</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.998387</td>\n",
       "      <td>0.998217</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>0.999067</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>0.999170</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.999200</td>\n",
       "      <td>0.998963</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996039</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997931</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995870</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_knn</th>\n",
       "      <td>0.997963</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.998933</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.998845</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_log</th>\n",
       "      <td>0.997793</td>\n",
       "      <td>0.997821</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.998845</td>\n",
       "      <td>0.998860</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.998550</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996039</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997931</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995870</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996039</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997931</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995870</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gboost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996039</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997931</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995870</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.998896</td>\n",
       "      <td>0.998614</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.999422</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.999467</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc  Test Acc  Acc-diff  Train-F1   Test-F1   F1-diff  \\\n",
       "knn       0.998217  0.998614  0.000396  0.999067  0.999275  0.000208   \n",
       "logreg    0.998387  0.998217  0.000170  0.999156  0.999067  0.000089   \n",
       "dt        1.000000  1.000000  0.000000  1.000000  1.000000  0.000000   \n",
       "bag       1.000000  0.996039  0.003961  1.000000  0.997931  0.002069   \n",
       "bag_knn   0.997963  0.998416  0.000453  0.998933  0.999171  0.000238   \n",
       "bag_log   0.997793  0.997821  0.000028  0.998845  0.998860  0.000015   \n",
       "rf        1.000000  0.996039  0.003961  1.000000  0.997931  0.002069   \n",
       "et        1.000000  0.999406  0.000594  1.000000  0.999689  0.000311   \n",
       "ada       1.000000  0.996039  0.003961  1.000000  0.997931  0.002069   \n",
       "gboost    1.000000  0.996039  0.003961  1.000000  0.997931  0.002069   \n",
       "svc       0.998896  0.998614  0.000283  0.999422  0.999275  0.000148   \n",
       "\n",
       "         Train-Pres  Test-Pres  Pres-diff  Train_Recall  Test-Recall  \\\n",
       "knn        0.999022   0.998757   0.000265      0.999111     0.999793   \n",
       "logreg     0.999111   0.999170   0.000059      0.999200     0.998963   \n",
       "dt         1.000000   1.000000   0.000000      1.000000     1.000000   \n",
       "bag        1.000000   0.995870   0.004130      1.000000     1.000000   \n",
       "bag_knn    0.999022   0.998757   0.000265      0.998845     0.999585   \n",
       "bag_log    0.998667   0.998550   0.000118      0.999022     0.999171   \n",
       "rf         1.000000   0.995870   0.004130      1.000000     1.000000   \n",
       "et         1.000000   0.999793   0.000207      1.000000     0.999585   \n",
       "ada        1.000000   0.995870   0.004130      1.000000     1.000000   \n",
       "gboost     1.000000   0.995870   0.004130      1.000000     1.000000   \n",
       "svc        0.999378   0.998757   0.000621      0.999467     0.999793   \n",
       "\n",
       "         Recall_diff  \n",
       "knn         0.000681  \n",
       "logreg      0.000237  \n",
       "dt          0.000000  \n",
       "bag         0.000000  \n",
       "bag_knn     0.000741  \n",
       "bag_log     0.000148  \n",
       "rf          0.000000  \n",
       "et          0.000415  \n",
       "ada         0.000000  \n",
       "gboost      0.000000  \n",
       "svc         0.000326  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbalanced_class_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
